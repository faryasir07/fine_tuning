# ğŸ§  Qwen2-VL Fine-tuning on LaTeX Image-Text Dataset

This project demonstrates how to fine-tune Alibabaâ€™s [Qwen2-VL](https://huggingface.co/Qwen/Qwen2-VL) vision-language model to understand and generate LaTeX code from complex images.

> ğŸ“ Notebook hosted on: [Kaggle Notebook Link](https://www.kaggle.com/code/yasirfarooqui07/qwen2-vl-finetune-latex)

## ğŸ“š Objective

- Fine-tune `Qwen2-VL` to generate LaTeX code from visual prompts.
- Leverage visual tokenization with `unsloth`, LoRA, and Hugging Face's trainer.

## ğŸš€ Features

- Uses `Unsloth` for optimized memory-efficient fine-tuning
- LoRA-based parameter-efficient training
- Mixed image-text support
- Notebook-friendly, Kaggle GPU-ready setup

## ğŸ›  Setup

You donâ€™t need to install anything on Kaggle â€” just enable GPU in settings.

If running locally:
```bash
pip install unsloth peft trl bitsandbytes transformers accelerate datasets
