{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T14:20:35.756366Z","iopub.execute_input":"2025-07-19T14:20:35.756636Z","iopub.status.idle":"2025-07-19T14:20:38.610870Z","shell.execute_reply.started":"2025-07-19T14:20:35.756610Z","shell.execute_reply":"2025-07-19T14:20:38.610223Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n!pip install --no-deps unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:14:29.971888Z","iopub.execute_input":"2025-07-20T05:14:29.972204Z","iopub.status.idle":"2025-07-20T05:14:44.790357Z","shell.execute_reply.started":"2025-07-20T05:14:29.972180Z","shell.execute_reply":"2025-07-20T05:14:44.789632Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nCollecting xformers==0.0.29.post3\n  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\nCollecting trl\n  Downloading trl-0.19.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\nCollecting cut_cross_entropy\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting unsloth_zoo\n  Downloading unsloth_zoo-2025.7.7-py3-none-any.whl.metadata (8.1 kB)\nDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.19.1-py3-none-any.whl (376 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading unsloth_zoo-2025.7.7-py3-none-any.whl (164 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.7/164.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: xformers, unsloth_zoo, trl, cut_cross_entropy, bitsandbytes\nSuccessfully installed bitsandbytes-0.46.1 cut_cross_entropy-25.1.1 trl-0.19.1 unsloth_zoo-2025.7.7 xformers-0.0.29.post3\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (3.20.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (0.1.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\nCollecting unsloth\n  Downloading unsloth-2025.7.5-py3-none-any.whl.metadata (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth-2025.7.5-py3-none-any.whl (298 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: unsloth\nSuccessfully installed unsloth-2025.7.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip uninstall unsloth unsloth_zoo -y\n!pip install unsloth --no-deps\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:07:56.456519Z","iopub.execute_input":"2025-07-20T05:07:56.457635Z","iopub.status.idle":"2025-07-20T05:07:59.847032Z","shell.execute_reply.started":"2025-07-20T05:07:56.457604Z","shell.execute_reply":"2025-07-20T05:07:59.846222Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: unsloth 2025.7.5\nUninstalling unsloth-2025.7.5:\n  Successfully uninstalled unsloth-2025.7.5\nFound existing installation: unsloth_zoo 2025.7.7\nUninstalling unsloth_zoo-2025.7.7:\n  Successfully uninstalled unsloth_zoo-2025.7.7\nCollecting unsloth\n  Using cached unsloth-2025.7.5-py3-none-any.whl.metadata (47 kB)\nUsing cached unsloth-2025.7.5-py3-none-any.whl (298 kB)\nInstalling collected packages: unsloth\nSuccessfully installed unsloth-2025.7.5\n","output_type":"stream"}],"execution_count":16},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"import unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:14:55.423137Z","iopub.execute_input":"2025-07-20T05:14:55.424124Z","iopub.status.idle":"2025-07-20T05:15:48.388050Z","shell.execute_reply.started":"2025-07-20T05:14:55.424089Z","shell.execute_reply":"2025-07-20T05:15:48.387226Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-20 05:15:15.680739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752988516.049743      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752988516.161844      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\nfrom unsloth import FastVisionModel\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:15:52.330222Z","iopub.execute_input":"2025-07-20T05:15:52.330533Z","iopub.status.idle":"2025-07-20T05:15:52.335064Z","shell.execute_reply.started":"2025-07-20T05:15:52.330510Z","shell.execute_reply":"2025-07-20T05:15:52.334399Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install unsloth_zoo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:08:52.880817Z","iopub.execute_input":"2025-07-20T05:08:52.881104Z","iopub.status.idle":"2025-07-20T05:09:52.616094Z","shell.execute_reply.started":"2025-07-20T05:08:52.881081Z","shell.execute_reply":"2025-07-20T05:09:52.614963Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth_zoo\n  Using cached unsloth_zoo-2025.7.7-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.6.0+cu124)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (25.0)\nCollecting tyro (from unsloth_zoo)\n  Downloading tyro-0.9.26-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.52.4)\nRequirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.8.1)\nRequirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.19.1)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.15.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.20.3)\nRequirement already satisfied: huggingface_hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.33.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.1.9)\nRequirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (25.1.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (11.2.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2024.11.6)\nCollecting msgspec (from unsloth_zoo)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.14.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.32.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.5.8)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth_zoo)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth_zoo) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth_zoo) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,>=4.51.3->unsloth_zoo) (0.21.2)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro->unsloth_zoo)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (4.4.4)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.12.13)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.6.15)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth_zoo) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.20.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth_zoo) (1.17.0)\nUsing cached unsloth_zoo-2025.7.7-py3-none-any.whl (164 kB)\nDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tyro-0.9.26-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, msgspec, nvidia-cusparse-cu12, tyro, nvidia-cusolver-cu12, unsloth_zoo\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed msgspec-0.19.0 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 shtab-1.7.2 tyro-0.9.26 unsloth_zoo-2025.7.7\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"fourbit_models = [\n    \"unsloth/Llama-3.2-11B-Vision-Instruct-bnb-4bit\",\n    \"unsloth/Qwen2-VL-7B-Instruct-bnb-4bit\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:16:10.702811Z","iopub.execute_input":"2025-07-20T05:16:10.703355Z","iopub.status.idle":"2025-07-20T05:16:10.706901Z","shell.execute_reply.started":"2025-07-20T05:16:10.703322Z","shell.execute_reply":"2025-07-20T05:16:10.706337Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model, tokenizer = FastVisionModel.from_pretrained(\n    \"unsloth/Qwen2-VL-7B-Instruct\",\n    load_in_4bit=True,\n    use_gradient_checkpointing=\"unsloth\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:16:12.870914Z","iopub.execute_input":"2025-07-20T05:16:12.871523Z","iopub.status.idle":"2025-07-20T05:16:58.859161Z","shell.execute_reply.started":"2025-07-20T05:16:12.871499Z","shell.execute_reply":"2025-07-20T05:16:58.858524Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.7.5: Fast Qwen2_Vl patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca4c5db3db664e63a7ed51bb63078fab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82aa0766d76d4da0abf1557dcbf5bc9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/572 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf752fadd9ba4ab8a1e4db50ffdf26d8"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ef63792c0b462f884a3d1e99b0eac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484768c0aa9d4d93af35a3708735d39c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184ae136bb92479a8e1e4ca43471a4a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eded5d0ba444efab466b82abab66d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/392 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e54be2e55bfc491c978a03036fca9964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6356bf07d6b1457f9dba22a18cd908d7"}},"metadata":{}},{"name":"stderr","text":"You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"chat_template.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf86541dc5a4172889ca4f861fac1ab"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model = FastVisionModel.get_peft_model(\n    model,\n    finetune_vision_layers=True,\n    finetune_language_layers=True,\n    finetune_attention_modules=True,\n    finetune_mlp_modules=True,\n\n    r=16,\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    random_state = 3407,\n    use_rslora=False,\n    loftq_config=None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:18:28.692329Z","iopub.execute_input":"2025-07-20T05:18:28.693240Z","iopub.status.idle":"2025-07-20T05:18:34.419877Z","shell.execute_reply.started":"2025-07-20T05:18:28.693211Z","shell.execute_reply":"2025-07-20T05:18:34.419073Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model.visual` require gradients\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"unsloth/LaTex_OCR\", split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:18:41.407451Z","iopub.execute_input":"2025-07-20T05:18:41.407754Z","iopub.status.idle":"2025-07-20T05:18:48.158948Z","shell.execute_reply.started":"2025-07-20T05:18:41.407731Z","shell.execute_reply":"2025-07-20T05:18:48.158393Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/519 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea8c62d1caa4c29a8a3fc6aff3ddc05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/344M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54def80f55b843138b55f36cc49a9227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/38.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbabbe678064a7b89cd1de08f583f9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/68686 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02382e2ea59f4cb6a422354a5fbefe03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7632 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e6c98f5093443d49daa57a67f0a7aa8"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:18:58.606365Z","iopub.execute_input":"2025-07-20T05:18:58.606680Z","iopub.status.idle":"2025-07-20T05:18:58.612000Z","shell.execute_reply.started":"2025-07-20T05:18:58.606656Z","shell.execute_reply":"2025-07-20T05:18:58.611331Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['image', 'text'],\n    num_rows: 68686\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset[0][\"image\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:00.460743Z","iopub.execute_input":"2025-07-20T05:19:00.461514Z","iopub.status.idle":"2025-07-20T05:19:00.510933Z","shell.execute_reply.started":"2025-07-20T05:19:00.461486Z","shell.execute_reply":"2025-07-20T05:19:00.510399Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAKAAAAAoCAIAAAD2TmbPAAALJ0lEQVR4Ae3aWYxURRcH8A9BBXeR4AJuDxJCUPHBfQU0ChFBRGJIkBhURIwLIm5RBIkmbOqDD8oWQAgkCiq4JMKwKeAGJmpCFEWIUWNwQUUFFb/fePJd79zuGaGn+/bIRz3crnu6qs6/zlan6lazP//88z97y54rgRb1TS1RfLNmzaJNQvGaEOvrXiF6gqEQQAN/VQhMetiEe5pYCDL9bz71ZkWRpXnv3Llzn332SVOaYL1pgmwKqIorGLLNmze3atXqoIMOOvDAA2k0KIceemjz5s2//fbb4447Ln+ts8XPPvts//33h8pTCVND5ys//fTTb7/9tnXr1vyxJcDI5+uvvyYrojvssMMOOOCAqjtDcdfcsWPHwoULBw8efMIJJ7zxxhsmgPL888+fdtpp7du3X7BgAVHmD/3XX3995ZVX7rrrrmOPPfaJJ54AAIw//viDdletWnXiiSeefPLJVcEG2Msvv3zHHXdQ6ty5c4nutttua9OmDbREB2H+svqbIwSZwgCD0rZtW+0uuOACr0TpedZZZ82aNUsF6GiT2xOqYNqnTx+oHnroIay3b9/O8n744Yezzz4bcdSoUYgBNX9gF1988XnnnRd8f/nll0svvbRFixbbtm2DXMkNT4ZRcQ8mrPXr1xPliBEjVqxYUVNTA+t333331VdfXXPNNeE02uRcLAo///wzMPhaKTx///33fffdd/LkyVu2bGnZsuXtt98OW/5rB474Ll68+Pzzz2dzDA4Y8Rk8qq1uqlVEwWCR3ZNPPinIDBo0SP2FF17wFP369++vwkbyB01SWD/33HO0eNlll3355ZcohGjhEJ8HDhxIxFY+is8ZWwB77bXXsCYfmcEhhxxCYsTVq1cv9lddHRdRMAGF7Dp06NC5c+czzzxzypQplPrhhx+KPFxZnaxzLvSHo4SAFsnx6aefFpwFwEmTJg0YMODxxx+/5ZZb9ttvP/E5ZwUHMEamMnv2bDCGDh3KMS6//HI6BilnPBm9ZBVMeVQoI50zZ86VV15J0xMnThQYR48e/eOPP9566636a5AZpdKvgYo6Oe6wYcM2bdokzAiDEi55X9++fSX24k3+ogxgkqw333xTbk9EKOLKxx9/LNWKdSR/VHXUAVC60KiyYcMGCzA1q1tUjjjiCCjtAVA0Rkx3yaFei2nnTmvbkUceid3DDz8sEgLZo0cP8MaMGWNKdJw/NqiCKQB33nlnRhTxb4aY82vWg3kGXc6YMUNwtgNmm8zQBgAsqT/bLEsMNEjRUsf0Ui8kBdWyZctuuOEG5Ouuu+7oo4++9tprhw8fLgZS/MEHH3z44YenepRYLYoKsb7hAPOX+MzgbN7URTsyJC71Rvru7oIpDjJjUAb96KOPjj/++Kuvvvqbb77hH+ZAgjqL0hpb+TJdcnjFFCrua/XlqQIJPDJ80ly3bp26ZfiTTz6BNgcwaRYc4NNPP7WzgGHt2rWwEZeSblPdevYkiyifeuqpL774wp7dDtj+kj1adJcuXdqpU6eIkP9omNINkzTnKDLJqJiqvtTw2GOPEQ0D0gwllk//3nPPPVbWaPa/3rW/gcoCbJm46KKLzjjjjHHjxlHwW2+9xXvoWy9L4PXXX58cb6W7J/VKAJPuSQ4gBMA5AYmZ1K5s1coOJplmupJVcPq/stdDc+IBPRlcvGU65klGXhnQu+++yxpI5x9tqLzYmhSw8oIpkg/HEkLEBK2EKKlBvWG5J55nt8rjLd568a2xY8eGXyZaoeBnnnnGRgLlpptusvPRYOrUqZ66FOWSQWUpiS1mxMPoUl96X2lgZhEs/hJYNq1JZh2VioLJ8PJaR8F4I0Vyn6CJSmg6GgQlowZ/KQLvJZdcQtCOhelAG8Ronzyp6phjjunevbsGL774ohXBX3fffbf4FmpLWiYVg2RQYYFo/AxdlyoCwz0z3zzBJOKqUwGoLMUixJlsTE8//fSGB9TMNx9PS5fsFxonfLElC3dsuPvu/tukgOUP5m8PI7jvv//es6jbpY0iGoirStCjl8PqU045xWETtcmkwuk1zhxBaKyXBFjy6XuLZkuWLHFMT+tCd8bktfyXAstZSmkFpeu1ITrUw5/OOeccZzGBLN0oU7f4iaX2oErk2NGAqiRQIq1K6MnIlP3222/LMIOLlroYYcKECYsWLfI6f/58Hozvueeeu3LlStl7jGmQfzWwikqpdevWiTwz2sm81io4lOFYw5ZDt6RFw0OE+6bzGgHWOXviwY4gYoS4MhBc5FBm/vrrrzsBVendu/cVV1yBo/zZx3wLKr3qGBgywLwm8GLk9DMmgpI/sLTETNCrWSgqZQezceNGcks4/nOFRMpSdmV1YQG800IQn28p3qmyL31c2ZEyiQgMvk7ed999y5cvh0rjxmNrUsAaD4ZHyVeIZRfzldr4nBR9FDboVOjzzz+nCZ+Pghh0LQVh5zWObzRLOqpEA+0pr0uXLqL3+++/77jYUElL09Ny/PjxjiOcb1txpdPt2rWjaV571FFH+deeilXG9/xoH4OnYQQ8UV3FsT6oyZw10z5dcgDGLoMjsZj4zTff/Oyzz6IE5vKCcSAqWYnB0yPXV/876CXOTknTp08XaTnW/fffP3LkSBPgXuKnGC6oUo+DddPIHBvhEUFVL9J33ceYNHfjjTcmURfFVipxTRUUMcf4xCGg4eLWi4htkca3MByBN23aNI5u8faZQRdQX3rpJZtv34kNkt44GVypKLAYnN337NlTOunmEIP+4IMPCAckO3syCbGUC4yEJj1gDFvvM6P5sHfE0m7G6J4ZcLde6Zt5Ctfz5s3TMbGDZJAE3u7ej6kQsEDI7tnZhRdemByGq5D4Aw88gG8Sh9KzSOqVrtQJ0ZiFIGTU0iUQfZhD9OopLTrppJOYpO2QiSWBNwMxpmRW/C9KpoFXbQpLSEdwlsxrU3R8vfyFO2z33nuvYBDxyqdrFGEjBvcsLPpCVUZgBoQEU1t/RokjilmIMbgIdbQeogvYaUglgykcKj1sYT2r4DDJmTNnPvjggyKeOByCdjnhqquuEhLFTGKNyRQO13hKrKaYFp1JwLN7Fod9Rwp2bu3QrvsxgBU1i8ajMkIhMFpE9+EE9zVr1qgzaE8g6RgegTRJDtCrUrIKDjcaMmTIo48+aqmTs8EKpa2qFcX2y7fhsL6qwA14Qh+Z+prkdoejbMmaY21iBUzJBxhGODKpbt26ARPK/ot/LQB0RImktdlrbqgK517nZNzfNCqqVPFmTEAkncIS8MiuKvdjCoGJIly2pqaGjlXomMrDiUUX7usqoIQIZTdyosJpN5ISuOMZBsjomtrNmASeCpCmXPX7MeGUwhvlidKBMHlSuWSF7lFoPaHnX6njwUCDm8PNmNKMMlQrZbUDKfv9mBIg0Vao2X7SKuZ+p0sv7733ngNXqpUDdu3alfsWbttK4FV6l7RNCTJN82ZMgBScm9T9GK4pp5Pi2eWfeuqpjjhcwe/YsaMNiBTVXqO+VDEt80rX6xx0ULCvs42/GVO6uTXYE7yS78c0OHDpf/JgRzSvvvpqv379fAh37Lp69ep33nnHWZ64LSFlBOnj+tI5ldqzjoJLHeT/ul/o2NdPuYviY5rLC27AS+wfeeQRIbrwMC5PeWUVHBmBlZhhKoHPHBTBJLLBKpokeKQTSAJhnsKqjxfhAONfi4izIGfj7qsI3W4Zk1gIrb6+laZnFVxpfnvq+GzO1Dy5sqzKGVa8Vle7MOxVcKVMLgl4lWKwa+PW2SbtWpe9rRqSAL0qWlTddwPlXg9uSFt7wH97PXgPUGJDU/gvIAEpGThc4fkAAAAASUVORK5CYII=","image/jpeg":"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"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"dataset[0][\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:03.356659Z","iopub.execute_input":"2025-07-20T05:19:03.357275Z","iopub.status.idle":"2025-07-20T05:19:03.363059Z","shell.execute_reply.started":"2025-07-20T05:19:03.357233Z","shell.execute_reply":"2025-07-20T05:19:03.362232Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"instruction = \"Write the LaTex representation for this image.\"\ndef convert_to_conversation(sample):\n  conversation = [\n      {\"role\": \"user\",\n       \"content\": [\n           {\"type\": \"text\", \"text\": instruction},\n           {\"type\": \"image\", \"image\": sample[\"image\"]}\n       ]\n       },\n      {\"role\": \"assistant\",\n       \"content\": [\n           {\"type\": \"text\", \"text\": sample[\"text\"]}\n       ]\n       }\n  ]\n  return {\"messages\": conversation}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:05.842759Z","iopub.execute_input":"2025-07-20T05:19:05.843318Z","iopub.status.idle":"2025-07-20T05:19:05.847673Z","shell.execute_reply.started":"2025-07-20T05:19:05.843292Z","shell.execute_reply":"2025-07-20T05:19:05.846979Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"convert_to_conversation(dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:08.710157Z","iopub.execute_input":"2025-07-20T05:19:08.710871Z","iopub.status.idle":"2025-07-20T05:19:08.717277Z","shell.execute_reply.started":"2025-07-20T05:19:08.710834Z","shell.execute_reply":"2025-07-20T05:19:08.716510Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'messages': [{'role': 'user',\n   'content': [{'type': 'text',\n     'text': 'Write the LaTex representation for this image.'},\n    {'type': 'image',\n     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>}]},\n  {'role': 'assistant',\n   'content': [{'type': 'text',\n     'text': '{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'}]}]}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"converted_dataset = [convert_to_conversation(sample) for sample in dataset]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:11.410717Z","iopub.execute_input":"2025-07-20T05:19:11.410993Z","iopub.status.idle":"2025-07-20T05:19:36.113905Z","shell.execute_reply.started":"2025-07-20T05:19:11.410970Z","shell.execute_reply":"2025-07-20T05:19:36.113157Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"converted_dataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:42.421447Z","iopub.execute_input":"2025-07-20T05:19:42.421760Z","iopub.status.idle":"2025-07-20T05:19:42.427086Z","shell.execute_reply.started":"2025-07-20T05:19:42.421738Z","shell.execute_reply":"2025-07-20T05:19:42.426396Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'messages': [{'role': 'user',\n   'content': [{'type': 'text',\n     'text': 'Write the LaTex representation for this image.'},\n    {'type': 'image',\n     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x50>}]},\n  {'role': 'assistant',\n   'content': [{'type': 'text',\n     'text': 'D _ { \\\\mu } ^ { \\\\alpha \\\\beta } \\\\bar { A } _ { \\\\mu } ^ { \\\\alpha \\\\beta } = 0 ,'}]}]}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"FastVisionModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:45.326431Z","iopub.execute_input":"2025-07-20T05:19:45.326939Z","iopub.status.idle":"2025-07-20T05:19:45.358242Z","shell.execute_reply.started":"2025-07-20T05:19:45.326918Z","shell.execute_reply":"2025-07-20T05:19:45.357518Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2VLForConditionalGeneration(\n      (model): Qwen2VLModel(\n        (visual): Qwen2VisionTransformerPretrainedModel(\n          (patch_embed): PatchEmbed(\n            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n          )\n          (rotary_pos_emb): VisionRotaryEmbedding()\n          (blocks): ModuleList(\n            (0-18): 19 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (19): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (20-21): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (22): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (23-28): 6 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (29): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (30-31): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n          )\n          (merger): PatchMerger(\n            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n            (mlp): Sequential(\n              (0): Linear(in_features=5120, out_features=5120, bias=True)\n              (1): GELU(approximate='none')\n              (2): Linear(in_features=5120, out_features=3584, bias=True)\n            )\n          )\n        )\n        (language_model): Qwen2VLTextModel(\n          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n          (layers): ModuleList(\n            (0-27): 28 x Qwen2VLDecoderLayer(\n              (self_attn): Qwen2VLSdpaAttention(\n                (q_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (v_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (rotary_emb): Qwen2VLRotaryEmbedding()\n              )\n              (mlp): Qwen2MLP(\n                (gate_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (up_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (down_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=18944, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act_fn): SiLU()\n              )\n              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n            )\n          )\n          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n          (rotary_emb): Qwen2VLRotaryEmbedding()\n        )\n      )\n      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"image = dataset[1][\"image\"]\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"text\", \"text\": instruction},\n            {\"type\": \"image\", \"image\": image}\n        ]\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:19:56.622893Z","iopub.execute_input":"2025-07-20T05:19:56.623613Z","iopub.status.idle":"2025-07-20T05:19:56.627875Z","shell.execute_reply.started":"2025-07-20T05:19:56.623590Z","shell.execute_reply":"2025-07-20T05:19:56.627193Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\ninputs = tokenizer(\n    image, input_text,\n    add_special_tokens = False,\n    return_tensors = \"pt\",\n).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:20:09.682140Z","iopub.execute_input":"2025-07-20T05:20:09.682836Z","iopub.status.idle":"2025-07-20T05:20:09.737006Z","shell.execute_reply.started":"2025-07-20T05:20:09.682810Z","shell.execute_reply":"2025-07-20T05:20:09.736500Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt=True)\n_ = model.generate(**inputs, streamer= text_streamer, max_new_tokens = 128, use_cache=True, temperature=1.5, min_p=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:20:11.228563Z","iopub.execute_input":"2025-07-20T05:20:11.229183Z","iopub.status.idle":"2025-07-20T05:20:50.516156Z","shell.execute_reply.started":"2025-07-20T05:20:11.229158Z","shell.execute_reply":"2025-07-20T05:20:50.515395Z"}},"outputs":[{"name":"stdout","text":"The LaTeX representation for the image is:\n\n```latex\nD^{\\mu}_{\\mu} \\tilde{A}^{\\mu}_{\\mu} = 0,\n```<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:20:53.071214Z","iopub.execute_input":"2025-07-20T05:20:53.071866Z","iopub.status.idle":"2025-07-20T05:20:53.077105Z","shell.execute_reply.started":"2025-07-20T05:20:53.071843Z","shell.execute_reply":"2025-07-20T05:20:53.076298Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x50>","image/png":"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","image/jpeg":"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"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from unsloth import is_bf16_supported\nfrom unsloth.trainer import UnslothVisionDataCollator\nfrom trl import SFTTrainer, SFTConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:21:06.153538Z","iopub.execute_input":"2025-07-20T05:21:06.154073Z","iopub.status.idle":"2025-07-20T05:21:06.157777Z","shell.execute_reply.started":"2025-07-20T05:21:06.154050Z","shell.execute_reply":"2025-07-20T05:21:06.157068Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"FastVisionModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:21:13.883451Z","iopub.execute_input":"2025-07-20T05:21:13.884068Z","iopub.status.idle":"2025-07-20T05:21:13.915600Z","shell.execute_reply.started":"2025-07-20T05:21:13.884044Z","shell.execute_reply":"2025-07-20T05:21:13.914868Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2VLForConditionalGeneration(\n      (model): Qwen2VLModel(\n        (visual): Qwen2VisionTransformerPretrainedModel(\n          (patch_embed): PatchEmbed(\n            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n          )\n          (rotary_pos_emb): VisionRotaryEmbedding()\n          (blocks): ModuleList(\n            (0-18): 19 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (19): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (20-21): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (22): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (23-28): 6 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (29): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (30-31): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n          )\n          (merger): PatchMerger(\n            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n            (mlp): Sequential(\n              (0): Linear(in_features=5120, out_features=5120, bias=True)\n              (1): GELU(approximate='none')\n              (2): Linear(in_features=5120, out_features=3584, bias=True)\n            )\n          )\n        )\n        (language_model): Qwen2VLTextModel(\n          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n          (layers): ModuleList(\n            (0-27): 28 x Qwen2VLDecoderLayer(\n              (self_attn): Qwen2VLSdpaAttention(\n                (q_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (v_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (rotary_emb): Qwen2VLRotaryEmbedding()\n              )\n              (mlp): Qwen2MLP(\n                (gate_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (up_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (down_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=18944, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act_fn): SiLU()\n              )\n              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n            )\n          )\n          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n          (rotary_emb): Qwen2VLRotaryEmbedding()\n        )\n      )\n      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model = model,\n    tokenizer=tokenizer,\n    data_collator = UnslothVisionDataCollator(model, tokenizer),\n    train_dataset = converted_dataset,\n    args = SFTConfig(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        warmup_steps = 5,\n        max_steps=30,\n        learning_rate=2e-4,\n        fp16=not is_bf16_supported(),\n        bf16 = is_bf16_supported(),\n        logging_steps=1,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n        report_to = \"none\",\n        remove_unused_columns=False,\n        dataset_text_field=\"\",\n        dataset_kwargs = {\"skip_prepare_dataset\": True},\n        dataset_num_proc=4,\n        max_seq_length=2048,\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:21:35.459584Z","iopub.execute_input":"2025-07-20T05:21:35.460227Z","iopub.status.idle":"2025-07-20T05:21:35.716774Z","shell.execute_reply.started":"2025-07-20T05:21:35.460200Z","shell.execute_reply":"2025-07-20T05:21:35.716139Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Model does not have a default image size - using 512\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:21:45.475047Z","iopub.execute_input":"2025-07-20T05:21:45.475395Z","iopub.status.idle":"2025-07-20T05:27:20.939403Z","shell.execute_reply.started":"2025-07-20T05:21:45.475372Z","shell.execute_reply":"2025-07-20T05:27:20.938738Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 68,686 | Num Epochs = 1 | Total steps = 30\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 50,855,936 of 8,342,231,552 (0.61% trained)\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 04:36, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.251400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.269900</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.276300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.153900</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.890500</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.867000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.616500</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.507700</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.296000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.263100</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.259000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.193100</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.183900</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.219900</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.133900</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.148200</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.140700</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.099700</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.113700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.123500</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.114500</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.161500</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.132600</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.132800</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.110400</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.095400</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.106200</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.121000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.148900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30, training_loss=0.37653828635811804, metrics={'train_runtime': 329.7817, 'train_samples_per_second': 1.456, 'train_steps_per_second': 0.091, 'total_flos': 3837549149933568.0, 'train_loss': 0.37653828635811804})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"FastVisionModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:27:46.637932Z","iopub.execute_input":"2025-07-20T05:27:46.639183Z","iopub.status.idle":"2025-07-20T05:27:46.672846Z","shell.execute_reply.started":"2025-07-20T05:27:46.639155Z","shell.execute_reply":"2025-07-20T05:27:46.671978Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2VLForConditionalGeneration(\n      (model): Qwen2VLModel(\n        (visual): Qwen2VisionTransformerPretrainedModel(\n          (patch_embed): PatchEmbed(\n            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n          )\n          (rotary_pos_emb): VisionRotaryEmbedding()\n          (blocks): ModuleList(\n            (0-18): 19 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (19): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (20-21): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (22): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (23-28): 6 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (29): Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n            (30-31): 2 x Qwen2VLVisionBlock(\n              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n              (attn): VisionSdpaAttention(\n                (qkv): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=3840, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3840, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (proj): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n              (mlp): VisionMlp(\n                (fc1): lora.Linear(\n                  (base_layer): Linear(in_features=1280, out_features=5120, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=1280, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=5120, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act): QuickGELUActivation()\n                (fc2): lora.Linear(\n                  (base_layer): Linear(in_features=5120, out_features=1280, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=5120, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=1280, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n              )\n            )\n          )\n          (merger): PatchMerger(\n            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n            (mlp): Sequential(\n              (0): Linear(in_features=5120, out_features=5120, bias=True)\n              (1): GELU(approximate='none')\n              (2): Linear(in_features=5120, out_features=3584, bias=True)\n            )\n          )\n        )\n        (language_model): Qwen2VLTextModel(\n          (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n          (layers): ModuleList(\n            (0-27): 28 x Qwen2VLDecoderLayer(\n              (self_attn): Qwen2VLSdpaAttention(\n                (q_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (v_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (rotary_emb): Qwen2VLRotaryEmbedding()\n              )\n              (mlp): Qwen2MLP(\n                (gate_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (up_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3584, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=18944, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (down_proj): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Identity()\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=18944, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3584, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (act_fn): SiLU()\n              )\n              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n            )\n          )\n          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n          (rotary_emb): Qwen2VLRotaryEmbedding()\n        )\n      )\n      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"image = dataset[2][\"image\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:28:27.487503Z","iopub.execute_input":"2025-07-20T05:28:27.487773Z","iopub.status.idle":"2025-07-20T05:28:27.492846Z","shell.execute_reply.started":"2025-07-20T05:28:27.487756Z","shell.execute_reply":"2025-07-20T05:28:27.492059Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"instruction = \"Write the LaTeX representation for this image.\"\nmessages = [\n    {\"role\": \"user\", \"content\": [\n        {\"type\": \"image\"},\n        {\"type\": \"text\", \"text\": instruction}\n    ]}\n]\n\ninput_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\ninputs = tokenizer(\n    image,\n    input_text,\n    add_special_tokens=False,\n    return_tensors=\"pt\",\n).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:28:52.902133Z","iopub.execute_input":"2025-07-20T05:28:52.902686Z","iopub.status.idle":"2025-07-20T05:28:52.911166Z","shell.execute_reply.started":"2025-07-20T05:28:52.902658Z","shell.execute_reply":"2025-07-20T05:28:52.910450Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt=True)\n\n_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128, use_cache=True, temperature=1.5, min_p=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:29:10.483681Z","iopub.execute_input":"2025-07-20T05:29:10.484223Z","iopub.status.idle":"2025-07-20T05:29:24.349551Z","shell.execute_reply.started":"2025-07-20T05:29:10.484202Z","shell.execute_reply":"2025-07-20T05:29:24.348966Z"}},"outputs":[{"name":"stdout","text":"H ^ { \\prime } = \\beta N \\int d \\lambda \\left\\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\right\\} \\ .<|im_end|>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T05:29:26.897400Z","iopub.execute_input":"2025-07-20T05:29:26.897681Z","iopub.status.idle":"2025-07-20T05:29:26.903162Z","shell.execute_reply.started":"2025-07-20T05:29:26.897660Z","shell.execute_reply":"2025-07-20T05:29:26.902640Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<PIL.PngImagePlugin.PngImageFile image mode=RGB size=320x50>","image/png":"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","image/jpeg":"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"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}